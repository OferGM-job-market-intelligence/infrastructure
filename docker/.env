# ============================================
# Job Market Intelligence Platform
# Docker Compose Environment Variables
# ============================================

# MongoDB Atlas (Cloud Database)
# Get your connection string from: https://cloud.mongodb.com
MONGODB_URI=mongodb+srv://username:password@cluster.mongodb.net/job_market?retryWrites=true&w=majority
MONGODB_DB_NAME=job_market

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6380
REDIS_PASSWORD=
REDIS_DB=0
REDIS_MAX_RETRIES=3
REDIS_RETRY_DELAY=1000

# Kafka Configuration
KAFKA_BROKERS=localhost:9092
KAFKA_CLIENT_ID=job-market-platform
KAFKA_GROUP_ID=job-market-consumers
KAFKA_TOPICS_RAW_JOBS=jobs.raw
KAFKA_TOPICS_ENRICHED_JOBS=jobs.enriched
KAFKA_TOPICS_SKILL_TRENDS=skill.trends

# Elasticsearch Configuration
ELASTICSEARCH_URL=http://localhost:9200
ELASTICSEARCH_INDEX_PREFIX=logs-
ELASTICSEARCH_MAX_RETRIES=3

# Kibana Configuration
KIBANA_URL=http://localhost:5601

# AWS LocalStack Configuration (for local S3 simulation)
AWS_ENDPOINT=http://localhost:4566
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=test
AWS_SECRET_ACCESS_KEY=test
S3_BUCKET=job-market-data
S3_BUCKET_EXPORTS=job-market-exports

# ============================================
# Service-Specific Configuration
# ============================================

# Scraper Service
SCRAPE_INTERVAL=3600000          # 1 hour in milliseconds
SCRAPER_RATE_LIMIT_MAX=50        # Max requests per hour
SCRAPER_TIMEOUT=30000            # Request timeout in ms
SCRAPER_USER_AGENT=Mozilla/5.0 (compatible; JobMarketBot/1.0)

# NLP Service
NLP_BATCH_SIZE=10                # Jobs to process in parallel
NLP_CONFIDENCE_THRESHOLD=0.7     # Minimum confidence for skill extraction
SPACY_MODEL=en_core_web_lg       # spaCy model to use

# Aggregation Service
AGGREGATION_INTERVAL=900000      # 15 minutes in milliseconds
AGGREGATION_BATCH_SIZE=10000     # Jobs to process per batch
CACHE_TTL_TRENDS=900             # 15 minutes in seconds
CACHE_TTL_SALARY_STATS=900       # 15 minutes in seconds

# Auth Service
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
JWT_ACCESS_TOKEN_EXPIRY=15m      # Access token expiry
JWT_REFRESH_TOKEN_EXPIRY=7d      # Refresh token expiry
BCRYPT_COST=12                   # Password hashing cost
PASSWORD_MIN_LENGTH=8
LOGIN_RATE_LIMIT_MAX=5           # Max login attempts per minute

# API Gateway
API_PORT=4000
API_GRAPHQL_PATH=/graphql
API_PLAYGROUND_ENABLED=true      # Disable in production
API_CORS_ORIGIN=http://localhost:5173,http://localhost:3000
API_RATE_LIMIT_WINDOW=60000      # 1 minute in ms
API_RATE_LIMIT_MAX_REQUESTS=100  # Max requests per window

# Frontend
VITE_API_URL=http://localhost:4000
VITE_GRAPHQL_URL=http://localhost:4000/graphql
VITE_WS_URL=ws://localhost:4000/graphql

# ============================================
# External API Keys (Optional - for scraping)
# ============================================

# LinkedIn (if using official API)
LINKEDIN_CLIENT_ID=
LINKEDIN_CLIENT_SECRET=

# Indeed (if using official API)
INDEED_PUBLISHER_ID=

# NewsAPI (for job-related news)
NEWSAPI_KEY=

# ============================================
# Development & Debugging
# ============================================

NODE_ENV=development
LOG_LEVEL=info                   # error, warn, info, debug, trace
ENABLE_DEBUG_LOGS=false

# ============================================
# Production Overrides (use .env.production)
# ============================================

# Set these differently in production:
# - JWT_SECRET: Use cryptographically secure random string
# - MONGODB_URI: Point to production cluster
# - API_PLAYGROUND_ENABLED: false
# - NODE_ENV: production
# - LOG_LEVEL: warn